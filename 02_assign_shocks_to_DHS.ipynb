{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  # for notebooks\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "tqdm.pandas()\n",
    "\n",
    "# Set global variables\n",
    "PROJECT = r\"Z:\\Laboral\\World Bank\\Paper - Child mortality and Climate Shocks\"\n",
    "OUTPUTS = rf\"{PROJECT}\\Outputs\"\n",
    "DATA = rf\"{PROJECT}\\Data\"\n",
    "DATA_IN = rf\"{DATA}\\Data_in\"\n",
    "DATA_PROC = rf\"{DATA}\\Data_proc\"\n",
    "DATA_OUT = rf\"{DATA}\\Data_out\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to assign climate shocks from a date and a point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data = xr.open_dataset(rf\"{DATA_OUT}/Climate_shocks.nc\")\n",
    "dates = climate_data.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_climate_shock(from_date, to_date, lat, lon):\n",
    "    if pd.isna(from_date):\n",
    "        return np.nan\n",
    "    \n",
    "    # Filter point    \n",
    "    point_data = climate_data.sel(time=slice(from_date, to_date)).sel(lat=lat, lon=lon, method='nearest')\n",
    "    \n",
    "    # Get position of original data\n",
    "    lat = point_data.lat.item()\n",
    "    lon = point_data.lon.item()\n",
    "\n",
    "    # Filter by time\n",
    "    inutero_q1   = point_data.isel(time=slice(0,3))\n",
    "    inutero_q2   = point_data.isel(time=slice(3,6))\n",
    "    inutero_q3   = point_data.isel(time=slice(6,9))\n",
    "    born_1m      = point_data.isel(time=slice(9,10))\n",
    "    born_2to3m  = point_data.isel(time=slice(10,12))\n",
    "    born_3to6m  = point_data.isel(time=slice(12,15))\n",
    "    born_6to9m  = point_data.isel(time=slice(15,18))\n",
    "    born_9to12m = point_data.isel(time=slice(18,21))\n",
    "\n",
    "    # Compute min and max values for both variables\n",
    "    inutero_q1_max   = inutero_q1[\"standarized_precipitation\"].max().item()\n",
    "    inutero_q2_max   = inutero_q2[\"standarized_precipitation\"].max().item()\n",
    "    inutero_q3_max   = inutero_q3[\"standarized_precipitation\"].max().item()\n",
    "    born_1m_max      = born_1m[\"standarized_precipitation\"].max().item()\n",
    "    born_2to3m_max  = born_2to3m[\"standarized_precipitation\"].max().item()\n",
    "    born_3to6m_max  = born_3to6m[\"standarized_precipitation\"].max().item()\n",
    "    born_6to9m_max  = born_6to9m[\"standarized_precipitation\"].max().item()\n",
    "    born_9to12m_max = born_9to12m[\"standarized_precipitation\"].max().item()\n",
    "\n",
    "    inutero_q1_min   = inutero_q1[\"standarized_precipitation\"].min().item()\n",
    "    inutero_q2_min   = inutero_q2[\"standarized_precipitation\"].min().item()\n",
    "    inutero_q3_min   = inutero_q3[\"standarized_precipitation\"].min().item()\n",
    "    born_1m_min      = born_1m[\"standarized_precipitation\"].min().item()\n",
    "    born_2to3m_min  = born_2to3m[\"standarized_precipitation\"].min().item()\n",
    "    born_3to6m_min  = born_3to6m[\"standarized_precipitation\"].min().item()\n",
    "    born_6to9m_min  = born_6to9m[\"standarized_precipitation\"].min().item()\n",
    "    born_9to12m_min = born_9to12m[\"standarized_precipitation\"].min().item()\n",
    "\n",
    "    inutero_q1_m_max   = inutero_q1[\"standarized_precipitation_m\"].max().item()\n",
    "    inutero_q2_m_max   = inutero_q2[\"standarized_precipitation_m\"].max().item()\n",
    "    inutero_q3_m_max   = inutero_q3[\"standarized_precipitation_m\"].max().item()\n",
    "    born_1m_m_max      = born_1m[\"standarized_precipitation_m\"].max().item()\n",
    "    born_2to3m_m_max  = born_2to3m[\"standarized_precipitation_m\"].max().item()\n",
    "    born_3to6m_m_max  = born_3to6m[\"standarized_precipitation_m\"].max().item()\n",
    "    born_6to9m_m_max  = born_6to9m[\"standarized_precipitation_m\"].max().item()\n",
    "    born_9to12m_m_max = born_9to12m[\"standarized_precipitation_m\"].max().item()\n",
    "\n",
    "    inutero_q1_m_min   = inutero_q1[\"standarized_precipitation_m\"].min().item()\n",
    "    inutero_q2_m_min   = inutero_q2[\"standarized_precipitation_m\"].min().item()\n",
    "    inutero_q3_m_min   = inutero_q3[\"standarized_precipitation_m\"].min().item()\n",
    "    born_1m_m_min      = born_1m[\"standarized_precipitation_m\"].min().item()\n",
    "    born_2to3m_m_min  = born_2to3m[\"standarized_precipitation_m\"].min().item()\n",
    "    born_3to6m_m_min  = born_3to6m[\"standarized_precipitation_m\"].min().item()\n",
    "    born_6to9m_m_min  = born_6to9m[\"standarized_precipitation_m\"].min().item()\n",
    "    born_9to12m_m_min = born_9to12m[\"standarized_precipitation_m\"].min().item()\n",
    "\n",
    "    out_vars = (lat, lon, inutero_q1_max, inutero_q2_max, inutero_q3_max, born_1m_max, born_2to3m_max, born_3to6m_max, born_6to9m_max, born_9to12m_max, inutero_q1_min, inutero_q2_min, inutero_q3_min, born_1m_min, born_2to3m_min, born_3to6m_min, born_6to9m_min, born_9to12m_min, inutero_q1_m_max, inutero_q2_m_max, inutero_q3_m_max, born_1m_m_max, born_2to3m_m_max, born_3to6m_m_max, born_6to9m_m_max, born_9to12m_m_max, inutero_q1_m_min, inutero_q2_m_min, inutero_q3_m_min, born_1m_m_min, born_2to3m_m_min, born_3to6m_m_min, born_6to9m_m_min, born_9to12m_m_min)\n",
    "    return out_vars    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_climate_shock_old(from_date, to_date, lat, lon):\n",
    "    if pd.isna(from_date):\n",
    "        return np.nan\n",
    "    \n",
    "    # Filter point    \n",
    "    point_data = climate_data.sel(time=slice(from_date, to_date)).sel(lat=lat, lon=lon, method='nearest')\n",
    "    \n",
    "    # Get max and min values for standarized precipitation\n",
    "    max_prec = point_data[\"standarized_precipitation\"].max().item()\n",
    "    min_prec = point_data[\"standarized_precipitation\"].min().item()\n",
    "    max_prec_m = point_data[\"standarized_precipitation_m\"].max().item()\n",
    "    min_prec_m = point_data[\"standarized_precipitation_m\"].min().item()\n",
    "    \n",
    "    # Get position of original data\n",
    "    lat = point_data.lat.item()\n",
    "    lon = point_data.lon.item()\n",
    "    \n",
    "    return lat, lon, max_prec, min_prec, max_prec_m, min_prec_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "def get_climate_shock_prof():\n",
    "    date = np.random.choice(dates[12:-12])\n",
    "    from_date, to_date = date + pd.DateOffset(months=-9), date + pd.DateOffset(years=1)\n",
    "    lat, lon = np.random.uniform(-90, 90), np.random.uniform(-180, 180)\n",
    "    \n",
    "    get_climate_shock(from_date, to_date, lat, lon)    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f get_climate_shock_prof get_climate_shock_prof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit get_climate_shock_prof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open DHS data and add the shock data to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata(rf\"{DATA_IN}/DHS/DHSBirthsGlobalAnalysis_04172024.dta\")\n",
    "df['ID'] = df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dates variables:\n",
    "We considered a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datetime object from year and month\n",
    "df[\"day\"] = 1\n",
    "df[\"month\"] = df[\"chb_month\"].astype(float)\n",
    "df[\"year\"] = df[\"chb_year\"].astype(float)\n",
    "df[\"birthdate\"] = pd.to_datetime(df[[\"year\", \"month\",\"day\"]]).to_numpy()\n",
    "\n",
    "# Maximum range of dates\n",
    "df[\"from_date\"] = df[\"birthdate\"] + pd.DateOffset(months=-9) # From in utero (9 months before birth) \n",
    "df[\"to_date\"] = df[\"birthdate\"] + pd.DateOffset(years=1) # To the first year of life\n",
    "\n",
    "# Filter children from_date greater than 1990 (we only have climate data from 1990)\n",
    "df = df[df[\"from_date\"] > \"1990-01-01\"]\n",
    "\n",
    "# # Construct deathdate variable\n",
    "# df[\"deathdate\"] = df[df[\"child_agedeath\"]<=12].progress_apply(lambda x: x[\"birthdate\"] + pd.DateOffset(months=x[\"child_agedeath\"]), axis=1)\n",
    "\n",
    "# # Replace to_date with deathdate if the child died\n",
    "# df[\"to_date\"] = np.where((df[\"child_agedeath\"]<=12) & (df[\"deathdate\"]<df[\"to_date\"]), df[\"deathdate\"], df[\"to_date\"])\n",
    "\n",
    "# Filter children to_date smalle than 2021 (we only have climate data to 2020)\n",
    "df = df[df[\"to_date\"] < \"2021-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"day\", \"month\", \"year\", \"birthdate\", \"from_date\", \"to_date\", \"child_agedeath\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_cols = [\"lat_climate\", \"lon_climate\", \"prec_inutero_q1_max\", \"prec_inutero_q2_max\", \"prec_inutero_q3_max\", \"prec_born_1m_max\", \"prec_born_2to3m_max\", \"prec_born_3to6m_max\", \"prec_born_6to9m_max\", \"prec_born_9to12m_max\", \"prec_inutero_q1_min\", \"prec_inutero_q2_min\", \"prec_inutero_q3_min\", \"prec_born_1m_min\", \"prec_born_2to3m_min\", \"prec_born_3to6m_min\", \"prec_born_6to9m_min\", \"prec_born_9to12m_min\", \"prec_inutero_q1_m_max\", \"prec_inutero_q2_m_max\", \"prec_inutero_q3_m_max\", \"prec_born_1m_m_max\", \"prec_born_2to3m_m_max\", \"prec_born_3to6m_m_max\", \"prec_born_6to9m_m_max\", \"prec_born_9to12m_m_max\", \"prec_inutero_q1_m_min\", \"prec_inutero_q2_m_min\", \"prec_inutero_q3_m_min\", \"prec_born_1m_m_min\", \"prec_born_2to3m_m_min\", \"prec_born_3to6m_m_min\", \"prec_born_6to9m_m_min\", \"prec_born_9to12m_m_min\"]\n",
    "\n",
    "for n in tqdm(range(0, df.ID.max(), 10_000)):\n",
    "    if os.path.exists(rf\"{DATA_PROC}/births_climate_{n}.csv\"):\n",
    "        print(f\"births_climate_{n}.csv exists, moving to next iteration\")\n",
    "        continue\n",
    "    chunk = df.loc[(df.ID >= n) & (df.ID < n+10_000), ['ID', 'from_date', 'to_date', 'LATNUM', 'LONGNUM']].copy()\n",
    "    if chunk.shape[0]==0:\n",
    "        continue\n",
    "    climate_results = chunk[['from_date', 'to_date', 'LATNUM', 'LONGNUM']].apply(lambda s: get_climate_shock(s['from_date'], s['to_date'], s['LATNUM'], s['LONGNUM']), axis=1)\n",
    "    climate_results = climate_results.apply(pd.Series)\n",
    "    climate_results.columns = climate_cols\n",
    "    climate_results[\"ID\"] = chunk[\"ID\"]\n",
    "    climate_results.to_csv(rf\"{DATA_PROC}/births_climate_{n}.csv\")\n",
    "    \n",
    "# df[climate_cols] = climate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For debugging\n",
    "# chunk[['from_date', 'to_date', 'LATNUM', 'LONGNUM']].progress_apply(lambda s: get_climate_shock(s['from_date'], s['to_date'], s['LATNUM'], s['LONGNUM']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(rf\"{DATA_PROC}\") \n",
    "files = [f for f in files if f.startswith(\"births_climate_\")]\n",
    "data = []\n",
    "for file in tqdm(files):\n",
    "    df = pd.read_csv(rf\"{DATA_PROC}/{file}\")\n",
    "    data += [df]\n",
    "df = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"Unnamed: 0\")\n",
    "df.to_stata(rf\"{DATA_PROC}\\ClimateShocks_assigned.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pos = np.random.randint(0, 500000)\n",
    "pos = 428380      \n",
    "filtered2 = climate_data.standarized_precipitation.sel(lat=df.at[pos, \"LATNUM\"], lon=df.at[pos, \"LONGNUM\"], method=\"nearest\")\n",
    "filtered2.plot(figsize=(12, 2))\n",
    "\n",
    "plt.axhline(2, color=\"red\")\n",
    "plt.axhline(-2, color=\"red\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v000</th>\n",
       "      <th>v001</th>\n",
       "      <th>v002</th>\n",
       "      <th>v003</th>\n",
       "      <th>v007</th>\n",
       "      <th>...</th>\n",
       "      <th>mother_ageb_squ</th>\n",
       "      <th>mother_ageb_cub</th>\n",
       "      <th>mother_eduy_squ</th>\n",
       "      <th>mother_eduy_cub</th>\n",
       "      <th>birth_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>560.111145</td>\n",
       "      <td>13255.964844</td>\n",
       "      <td>256.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>774.694397</td>\n",
       "      <td>21562.326172</td>\n",
       "      <td>256.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>423.673645</td>\n",
       "      <td>8720.616211</td>\n",
       "      <td>64.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>604.340332</td>\n",
       "      <td>14856.699219</td>\n",
       "      <td>64.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>654.506897</td>\n",
       "      <td>16744.466797</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780579</th>\n",
       "      <td>ZW7</td>\n",
       "      <td>99</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>348.444427</td>\n",
       "      <td>6504.295410</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780580</th>\n",
       "      <td>ZW7</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>280.562500</td>\n",
       "      <td>4699.421875</td>\n",
       "      <td>64.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780581</th>\n",
       "      <td>ZW7</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>280.562500</td>\n",
       "      <td>4699.421875</td>\n",
       "      <td>64.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780582</th>\n",
       "      <td>ZW7</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>413.444458</td>\n",
       "      <td>8406.704102</td>\n",
       "      <td>64.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780583</th>\n",
       "      <td>ZW7</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>413.444458</td>\n",
       "      <td>8406.704102</td>\n",
       "      <td>64.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4780584 rows Ã— 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v000  v001  v002  v003  v007  ...  mother_ageb_squ mother_ageb_cub  \\\n",
       "0        AL5     1     1     3  2008  ...       560.111145    13255.964844   \n",
       "1        AL5     1     1     3  2008  ...       774.694397    21562.326172   \n",
       "2        AL5     1    10     4  2008  ...       423.673645     8720.616211   \n",
       "3        AL5     1    10     4  2008  ...       604.340332    14856.699219   \n",
       "4        AL5     1    12     3  2008  ...       654.506897    16744.466797   \n",
       "...      ...   ...   ...   ...   ...  ...              ...             ...   \n",
       "4780579  ZW7    99     8     3  2015  ...       348.444427     6504.295410   \n",
       "4780580  ZW7    99     9     1  2015  ...       280.562500     4699.421875   \n",
       "4780581  ZW7    99     9     1  2015  ...       280.562500     4699.421875   \n",
       "4780582  ZW7    99     9     1  2015  ...       413.444458     8406.704102   \n",
       "4780583  ZW7    99     9     1  2015  ...       413.444458     8406.704102   \n",
       "\n",
       "        mother_eduy_squ mother_eduy_cub birth_order  \n",
       "0                 256.0          4096.0         1.0  \n",
       "1                 256.0          4096.0         2.0  \n",
       "2                  64.0           512.0         1.0  \n",
       "3                  64.0           512.0         2.0  \n",
       "4                 144.0          1728.0         1.0  \n",
       "...                 ...             ...         ...  \n",
       "4780579           100.0          1000.0         2.0  \n",
       "4780580            64.0           512.0         1.0  \n",
       "4780581            64.0           512.0         2.0  \n",
       "4780582            64.0           512.0         3.0  \n",
       "4780583            64.0           512.0         4.0  \n",
       "\n",
       "[4780584 rows x 158 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
