{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318cd1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geocube\n",
    "import rioxarray \n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(n_workers=18)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7206e87",
   "metadata": {},
   "source": [
    "# Create Population Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e780c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process GPW data\n",
    "\n",
    "country_pop = pd.read_csv(r\"C:\\Working Papers\\Paper - Child Mortality and Climate Shocks\\Data\\Data_in\\UN Population Estimates\\unpopulation_dataportal_20250902202059.csv\")\n",
    "country_pop.loc[country_pop.IndicatorId == 49,\"Indicator\"] = \"Total Population\"\n",
    "country_pop.loc[country_pop.IndicatorId == 47,\"Indicator\"] = \"Total Births\"\n",
    "\n",
    "country_pop = country_pop[[\"Indicator\", \"LocationId\", \"Location\", \"Iso3\", 'Time', 'Value']]\n",
    "country_pop = country_pop.pivot(index=[\"LocationId\",\"Location\",\"Iso3\",\"Time\"], columns=\"Indicator\").reset_index()\n",
    "country_pop.columns = ['_'.join(col).replace('_', '') for col in country_pop.columns.values]\n",
    "country_pop[\"born_ratio\"] = country_pop[\"ValueTotal Births\"]  / country_pop[\"ValueTotal Population\"]  \n",
    "\n",
    "gpw_years = np.array([2000, 2005, 2010, 2015, 2020])\n",
    "country_pop['year_gpw'] = country_pop['Time'].apply(lambda y: gpw_years[np.abs(gpw_years - y).argmin()])\n",
    "country_pop = country_pop.groupby(by=['LocationId','Iso3','year_gpw']).born_ratio.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d15a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process GPW data\n",
    "\n",
    "# GPW map with IDs\n",
    "gpw_country_ids = gpd.read_file(r\"E:\\Datasets\\Gridded Population of the World\\15-minutes\\gpw_v4_national_identifier_grid_rev11_15_min.shp\")\n",
    "gpw_country_ids = gpw_country_ids[['Value', 'ISOCODE', 'NAME0', 'MEANUNITKM', 'geometry']]\n",
    "whole_world = gpw_country_ids[[\"geometry\"]].dissolve()\n",
    "# Add born_ratio to gpw_country_ids\n",
    "gpw_country_ids = gpw_country_ids.merge(country_pop, left_on=\"Value\", right_on=\"LocationId\", validate=\"1:m\", how=\"inner\")\n",
    "\n",
    "# Keep only the ones that are in DHS\n",
    "dhs = pd.read_stata(r\"C:\\Working Papers\\Paper - Child Mortality and Climate Shocks\\Data\\Data_in\\DHS\\DHSBirthsGlobalAnalysis_07272025.dta\")\n",
    "dhs_iso = dhs.code_iso3.unique().tolist()\n",
    "gpw_country_ids = gpw_country_ids[gpw_country_ids.ISOCODE.isin(dhs_iso)]\n",
    "print(f\"Number of countries: {gpw_country_ids.ISOCODE.unique()}\")\n",
    "\n",
    "# Clean columns\n",
    "gpw_country_ids = gpw_country_ids[[\"geometry\", \"year_gpw\", \"born_ratio\"]].rename(columns={\"year_gpw\":\"time\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81364121",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gridded Population of the World\n",
    "gpw_tifs_paths = [\n",
    "    r\"e:\\Datasets\\Gridded Population of the World\\15-minutes\\gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2020_15_min.tif\", \n",
    "    r\"e:\\Datasets\\Gridded Population of the World\\15-minutes\\gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2000_15_min.tif\", \n",
    "    r\"e:\\Datasets\\Gridded Population of the World\\15-minutes\\gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2005_15_min.tif\", \n",
    "    r\"e:\\Datasets\\Gridded Population of the World\\15-minutes\\gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2010_15_min.tif\", \n",
    "    r\"e:\\Datasets\\Gridded Population of the World\\15-minutes\\gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2015_15_min.tif\",\n",
    "]\n",
    "gpw_tifs_paths.sort()\n",
    "\n",
    "tifs = []\n",
    "\n",
    "for tif_path in gpw_tifs_paths:\n",
    "\n",
    "    # Load and clean tif\n",
    "    tif = rioxarray.open_rasterio(tif_path)\n",
    "    tif = tif.sel(band=1).drop_vars([\"band\", \"spatial_ref\"])\n",
    "    \n",
    "    # Add year\n",
    "    tif_year = tif_path.replace(\"_15_min.tif\", \"\")[-4:]\n",
    "    tif = tif.expand_dims(time=[int(tif_year)]) \n",
    "    tif.name = \"total_population\"\n",
    "    tifs += [tif]\n",
    "\n",
    "pop_dataset = xr.concat(tifs, dim=\"time\").to_dataset()\n",
    "pop_dataset[\"total_population\"] = pop_dataset.total_population.where(pop_dataset[\"total_population\"]>0, np.nan)\n",
    "pop_dataset = pop_dataset.rio.write_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1283eb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geocube.api.core import make_geocube\n",
    "\n",
    "grid_ds_years = []\n",
    "for year in gpw_country_ids.time.unique():\n",
    "    country_grid_ds_year = make_geocube(\n",
    "        vector_data=gpw_country_ids[gpw_country_ids.time == year],\n",
    "        measurements=['born_ratio'], # The column to burn into the raster\n",
    "        like=pop_dataset,          # Use this raster as a template for the output grid\n",
    "        fill=np.nan                     # The \"no data\" value for cells without a polygon\n",
    "    )\n",
    "    country_grid_ds_year = country_grid_ds_year.expand_dims(time=[int(year)]) \n",
    "    \n",
    "    grid_ds_years += [country_grid_ds_year]\n",
    "\n",
    "\n",
    "# # Extract the DataArray from the Dataset\n",
    "# country_grid = country_grid_ds['country_id']\n",
    "ratio_dataset = xr.concat(grid_ds_years, dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc259fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a single dataset with both variables\n",
    "dataset = xr.combine_by_coords([pop_dataset, ratio_dataset])\n",
    "dataset[\"total_population\"] = dataset[\"total_population\"].where(dataset[\"born_ratio\"].notnull(), np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7bce2c",
   "metadata": {},
   "source": [
    "# Create Climate map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load the datset ---\n",
    "\n",
    "climate_ds = xr.open_dataset(r\"C:\\Working Papers\\Paper - Child Mortality and Climate Shocks\\Data\\Data_out\\Climate_shocks_v11.nc\")\n",
    "climate_ds = climate_ds.sel(time=slice(\"01-01-1990\",\"12-31-2020\"))\n",
    "climate_ds = climate_ds[[\"stdm_t\"]]\n",
    "\n",
    "climate_ds_6m = climate_ds.rolling(time=6, center=False).mean()\n",
    "climate_ds_9m = climate_ds.rolling(time=9, center=False).mean()\n",
    "climate_ds_6m [\"stdm_t_pos_6m\"] = climate_ds_6m .stdm_t.where((climate_ds_6m .stdm_t > 0) | (climate_ds_6m .stdm_t.isnull()), 0)\n",
    "climate_ds_6m [\"stdm_t_neg_6m\"] = climate_ds_6m .stdm_t.where((climate_ds_6m .stdm_t < 0) | (climate_ds_6m .stdm_t.isnull()), 0)\n",
    "climate_ds_9m [\"stdm_t_pos_9m\"] = climate_ds_9m .stdm_t.where((climate_ds_9m .stdm_t > 0) | (climate_ds_9m .stdm_t.isnull()), 0)\n",
    "climate_ds_9m [\"stdm_t_neg_9m\"] = climate_ds_9m .stdm_t.where((climate_ds_9m .stdm_t < 0) | (climate_ds_9m .stdm_t.isnull()), 0)\n",
    "climate_ds_6m = climate_ds_6m.drop_vars([\"stdm_t\"])\n",
    "climate_ds_9m = climate_ds_9m.drop_vars([\"stdm_t\"])\n",
    "\n",
    "climate_ds = xr.combine_by_coords([climate_ds_6m, climate_ds_9m]).rename_dims({\"lat\":\"y\", \"lon\":\"x\"}).rename_vars({\"lat\":\"y\", \"lon\":\"x\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17985af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# Make monthly so it matches the climate_ds structure\n",
    "dataset[\"time\"] = pd.to_datetime(dataset.time, format=\"%Y\")\n",
    "dataset = dataset.interp_like(climate_ds, method=\"linear\", kwargs={\"fill_value\":\"extrapolate\"})\n",
    "dataset = xr.combine_by_coords([dataset, climate_ds])\n",
    "encoding = {\n",
    "    var: {\"zlib\": True, \"complevel\": 6} for var in dataset.data_vars\n",
    "}\n",
    "dataset.to_netcdf(r\"C:\\Working Papers\\Paper - Child Mortality and Climate Shocks\\Data\\Data_proc\\effect_map_variables_high_res.nc\", encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077ac790",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.open_dataset(r\"C:\\Working Papers\\Paper - Child Mortality and Climate Shocks\\Data\\Data_proc\\effect_map_variables_high_res.nc\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cceedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add climate bands\n",
    "kg_bands = xr.open_dataset(r\"E:\\Datasets\\KÃ¶ppen-Geiger Climate Classification\\KG_1986-2010.grd\", engine=\"rasterio\").band_data.sel(band=1)\n",
    "kg_bands = kg_bands.drop_vars([\"band\", \"spatial_ref\"])\n",
    "\n",
    "# Your list of \"category 3\" categories\n",
    "categories_3 = [\n",
    "    'Af', 'Am', 'As', 'Aw',\n",
    "    'BSh', 'BSk', 'BWh', 'BWk',\n",
    "    'Cfa', 'Cfb', 'Cfc', 'Csa', 'Csb', 'Csc', 'Cwa', 'Cwb', 'Cwc',\n",
    "    'Dfa', 'Dfb', 'Dfc', 'Dfd', 'Dsa', 'Dsb', 'Dsc', 'Dsd', 'Dwa', 'Dwb', 'Dwc', 'Dwd',\n",
    "    'EF', 'ET', 'Ocean'\n",
    "]\n",
    "\n",
    "# --- Create the DataArray for \"category 3\" ---\n",
    "\n",
    "# Create a new DataArray with the same dimensions and coordinates\n",
    "categorical_da_3 = xr.full_like(kg_bands, fill_value='', dtype=object)\n",
    "\n",
    "# Create a numpy array of the categories for efficient indexing\n",
    "category_array_3 = np.array(categories_3)\n",
    "\n",
    "# Map the integer values to the \"category 3\" strings\n",
    "# Subtract 1 because array indexing is 0-based\n",
    "categorical_da_3.values = category_array_3[kg_bands.values.astype(int) - 1]\n",
    "\n",
    "\n",
    "# --- Create the DataArray for \"category 1\" ---\n",
    "\n",
    "# Your mapping from \"category 3\" to \"category 1\"\n",
    "categories_3_to_1 = {\n",
    "    'Af': 1, 'Am': 1, 'As': 1, 'Aw': 1,\n",
    "    'BSh': 2, 'BSk': 2, 'BWh': 2, 'BWk': 2,\n",
    "    'Cfa': 3, 'Cfb': 3, 'Cfc': 3, 'Csa': 3, 'Csb': 3, 'Csc': 3, 'Cwa': 3, 'Cwb': 3, 'Cwc': 3,\n",
    "    'Dfa': 4, 'Dfb': 4, 'Dfc': 4, 'Dfd': 4, 'Dsa': 4, 'Dsb': 4, 'Dsc': 4, 'Dsd': 4, 'Dwa': 4, 'Dwb': 4, 'Dwc': 4, 'Dwd': 4,\n",
    "    'EF': np.nan, 'ET': np.nan, 'Ocean': np.nan,\n",
    "}\n",
    "\n",
    "# Create another new DataArray for the \"category 1\" data\n",
    "categorical_da_1 = xr.full_like(categorical_da_3, fill_value='', dtype=object)\n",
    "\n",
    "# A function to apply the mapping\n",
    "def map_func(val):\n",
    "    return categories_3_to_1.get(val)\n",
    "\n",
    "# Use xarray's apply_ufunc to efficiently apply the mapping\n",
    "categorical_da_1 = xr.apply_ufunc(np.vectorize(map_func), categorical_da_3)\n",
    "categorical_da_1.name = \"climate_band\"\n",
    "categorical_da_1 = categorical_da_1.interp_like(dataset, method=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e465a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get coefficients from the regressions: \n",
    "import numpy as np\n",
    "import plot_tools_b as pt\n",
    "import copy # Import the copy module\n",
    "\n",
    "\n",
    "def set_nonsignificant_to_zero(coeffs_dict):\n",
    "    \"\"\"\n",
    "    Sets coefficients to zero if their confidence interval crosses zero.\n",
    "\n",
    "    Args:\n",
    "        coeffs_dict (dict): A dictionary containing coefficient details\n",
    "                           (coef, lower, upper lists).\n",
    "\n",
    "    Returns:\n",
    "        dict: A new dictionary with non-significant coefficients set to 0.\n",
    "    \"\"\"\n",
    "    # Create a deep copy to avoid modifying the original dictionary\n",
    "    filtered_coeffs = copy.deepcopy(coeffs_dict)\n",
    "\n",
    "    # Iterate over each variable (e.g., 'inutero_b_avg_neg_int')\n",
    "    for key, values in filtered_coeffs.items():\n",
    "        coef_list = values['coef']\n",
    "        lower_list = values.get('lower', []) # Use .get for safety\n",
    "        upper_list = values.get('upper', [])\n",
    "\n",
    "        # Ensure all lists have the same length\n",
    "        if not (len(coef_list) == len(lower_list) == len(upper_list)):\n",
    "            print(f\"Warning: Mismatched list lengths in {key}. Skipping filtering.\")\n",
    "            continue\n",
    "\n",
    "        # Iterate over each individual coefficient in the list\n",
    "        for i in range(len(coef_list)):\n",
    "            lower_bound = lower_list[i]\n",
    "            upper_bound = upper_list[i]\n",
    "\n",
    "            # Check for NaNs, as they can't be compared\n",
    "            if np.isnan(lower_bound) or np.isnan(upper_bound):\n",
    "                continue\n",
    "\n",
    "            # The condition for non-significance: lower is negative AND upper is positive\n",
    "            if lower_bound < 0 and upper_bound > 0:\n",
    "                coef_list[i] = 0.0  # Set non-significant coefficient to zero\n",
    "\n",
    "    return filtered_coeffs\n",
    "\n",
    "all_climate_coeffs = {}\n",
    "for i, zone in enumerate([\"Tropical\", \"Arid\", \"Temperate\"]):\n",
    "\n",
    "    coefs = pt.extract_coefficients_and_CI_latex(fr\"C:\\Working Papers\\Paper - Child Mortality and Climate Shocks\\Outputs\\heterogeneity\\climate_band_1\\linear_dummies_true_spi1_b_avg_stdm_t semester - {zone} standard_fe standard_sym.tex\")\n",
    "    all_climate_coeffs[i+1] = set_nonsignificant_to_zero(coefs[\"temp\"][\"cell1\"])\n",
    "\n",
    "total_coeffs = {}\n",
    "\n",
    "for zone, coeffs in all_climate_coeffs.items():\n",
    "\n",
    "    # --- High Temperature (Positive Shocks) ---\n",
    "    # Sum of coefficients for in-utero and first year of life (1-12 months)\n",
    "    high_temp_iushocks = (\n",
    "        np.nansum(coeffs['inutero_b_avg_pos_int']['coef']) +\n",
    "        np.nansum(coeffs['born_1m6m_b_avg_pos_int']['coef']) +\n",
    "        np.nansum(coeffs['born_6m12m_b_avg_pos_int']['coef'])\n",
    "    )\n",
    "    # Sum of coefficients for ONLY the first year of life (1-12 months)\n",
    "    high_temp_1yearshock = (\n",
    "        np.nansum(coeffs['born_1m6m_b_avg_pos_int']['coef']) +\n",
    "        np.nansum(coeffs['born_6m12m_b_avg_pos_int']['coef'])\n",
    "    )\n",
    "\n",
    "    # --- Low Temperature (Negative Shocks) ---\n",
    "    # Sum of coefficients for in-utero and first year of life (1-12 months)\n",
    "    low_temp_iushocks = (\n",
    "        np.nansum(coeffs['inutero_b_avg_neg_int']['coef']) +\n",
    "        np.nansum(coeffs['born_1m6m_b_avg_neg_int']['coef']) +\n",
    "        np.nansum(coeffs['born_6m12m_b_avg_neg_int']['coef'])\n",
    "    )\n",
    "    # Sum of coefficients for ONLY the first year of life (1-12 months)\n",
    "    low_temp_1yearshock = (\n",
    "        np.nansum(coeffs['born_1m6m_b_avg_neg_int']['coef']) +\n",
    "        np.nansum(coeffs['born_6m12m_b_avg_neg_int']['coef'])\n",
    "    )\n",
    "\n",
    "    total_coeffs[zone] = {\n",
    "        'high_temp_iushocks': high_temp_iushocks.item(),\n",
    "        'high_temp_1yearshock': high_temp_1yearshock.item(),\n",
    "        'low_temp_iushocks': low_temp_iushocks.item(),\n",
    "        'low_temp_1yearshock': low_temp_1yearshock.item()\n",
    "    }\n",
    "\n",
    "# Print the results for one zone to verify\n",
    "print(\"Calculated coefficients for Zones:\")\n",
    "print(total_coeffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084bddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of looping over the large 3D dataset, we first create 2D maps \n",
    "# of the coefficients. This is much faster as it avoids building a deep Dask graph.\n",
    "\n",
    "climate_band = categorical_da_1\n",
    "# Initialize coefficient maps with NaNs, matching the spatial dimensions and chunking of the climate band map.\n",
    "# dataset['climate_band'] is 2D (y, x), so these maps will also be 2D.\n",
    "high_temp_iushocks_map = xr.full_like(climate_band, np.nan, dtype=float)\n",
    "high_temp_1yearshock_map = xr.full_like(climate_band, np.nan, dtype=float)\n",
    "low_temp_iushocks_map = xr.full_like(climate_band, np.nan, dtype=float)\n",
    "low_temp_1yearshock_map = xr.full_like(climate_band, np.nan, dtype=float)\n",
    "\n",
    "# Fill the maps. This loop is efficient because it operates on 2D arrays.\n",
    "for zone, values in total_coeffs.items():\n",
    "    print(zone)\n",
    "    print(f\"High Temp Attributable Deaths in the first year (in utero shocks): {values['high_temp_iushocks']}\")\n",
    "    print(f\"Low Temp Attributable Deaths in the first year (in utero shocks): {values['low_temp_iushocks']}\")\n",
    "    print(f\"High Temp Attributable Deaths in the first year (1st year shocks): {values['high_temp_1yearshock']}\")\n",
    "    print(f\"Low Temp Attributable Deaths in the first year (1st year shocks): {values['low_temp_1yearshock']}\")\n",
    "    \n",
    "    # Create a boolean mask where the climate band matches the current zone\n",
    "    mask = (climate_band == zone)\n",
    "\n",
    "    # Use .where() to fill in the values.\n",
    "    # da.where(condition, other) keeps values where condition is True, and replaces with 'other' where False.\n",
    "    # We use ~mask so we keep existing values where it does NOT match, and fill in the new coefficient where it DOES match.\n",
    "    high_temp_iushocks_map = high_temp_iushocks_map.where(~mask, values[\"high_temp_iushocks\"])\n",
    "    high_temp_1yearshock_map = high_temp_1yearshock_map.where(~mask, values[\"high_temp_1yearshock\"])\n",
    "    low_temp_iushocks_map = low_temp_iushocks_map.where(~mask, -values[\"low_temp_iushocks\"])\n",
    "    low_temp_1yearshock_map = low_temp_1yearshock_map.where(~mask, -values[\"low_temp_1yearshock\"])\n",
    "    assert high_temp_iushocks_map.max() > 0\n",
    "\n",
    "# --- Calculate deaths in a single vectorized operation ---\n",
    "# Xarray will automatically broadcast the 2D coefficient maps (y, x)\n",
    "# against the 3D climate data (time, y, x). This creates a much simpler Dask graph.\n",
    "dataset[\"pos_deaths_per_1000_childs\"] = (\n",
    "    dataset[\"stdm_t_pos_9m\"] * high_temp_iushocks_map +\n",
    "    dataset[\"stdm_t_pos_6m\"] * high_temp_1yearshock_map\n",
    ")\n",
    "\n",
    "dataset[\"neg_deaths_per_1000_childs\"] = (\n",
    "    dataset[\"stdm_t_neg_9m\"] * -low_temp_iushocks_map +\n",
    "    dataset[\"stdm_t_neg_6m\"] * -low_temp_1yearshock_map\n",
    ")\n",
    "\n",
    "# The rest of the calculations remain the same\n",
    "dataset[\"n_childs\"] = dataset[\"total_population\"] * dataset[\"born_ratio\"]\n",
    "dataset[\"pos_deaths\"] = dataset[\"n_childs\"] * dataset[\"pos_deaths_per_1000_childs\"] / 1000\n",
    "dataset[\"neg_deaths\"] = dataset[\"n_childs\"] * dataset[\"neg_deaths_per_1000_childs\"] / 1000\n",
    "\n",
    "dataset[\"pos_deaths_per_1000_childs\"] = dataset[\"pos_deaths_per_1000_childs\"].where(dataset[\"pos_deaths\"].notnull(), np.nan)\n",
    "dataset[\"neg_deaths_per_1000_childs\"] = dataset[\"neg_deaths_per_1000_childs\"].where(dataset[\"neg_deaths\"].notnull(), np.nan)\n",
    "dataset[\"deaths_per_1000_childs\"] = dataset[\"pos_deaths_per_1000_childs\"] + dataset[\"neg_deaths_per_1000_childs\"]\n",
    "\n",
    "dataset[\"total_deaths\"] = dataset[\"neg_deaths\"] + dataset[\"pos_deaths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1f824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"total_deaths\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b665c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Create a sample dataset for demonstration ---\n",
    "\n",
    "# # Map the calculated coefficients to the grid using the climate zone DataArray\n",
    "# dataset[\"pos_deaths_per_1000_childs\"] = np.nan\n",
    "# dataset[\"neg_deaths_per_1000_childs\"] = np.nan\n",
    "\n",
    "# for zone, values in total_coeffs.items():\n",
    "    \n",
    "#     high_temp_attributable_deaths_1year_iushocks = values[\"high_temp_iushocks\"]\n",
    "#     high_temp_attributable_deaths_1year_1yearshock = values[\"high_temp_1yearshock\"]\n",
    "#     low_temp_attributable_deaths_1year_iushocks =  values[\"low_temp_iushocks\"]\n",
    "#     low_temp_attributable_deaths_1year_1yearshock = values[\"low_temp_1yearshock\"]\n",
    "\n",
    "#     print(zone)\n",
    "#     print(f\"High Temp Attributable Deaths in the first year (in utero shocks): {high_temp_attributable_deaths_1year_iushocks}\")\n",
    "#     print(f\"Low Temp Attributable Deaths in the first year (in utero shocks): {low_temp_attributable_deaths_1year_iushocks}\")\n",
    "#     print(f\"High Temp Attributable Deaths in the first year (1st year shocks): {high_temp_attributable_deaths_1year_1yearshock}\")\n",
    "#     print(f\"Low Temp Attributable Deaths in the first year (1st year shocks): {low_temp_attributable_deaths_1year_1yearshock}\")\n",
    "    \n",
    "#     dataset[\"pos_deaths_per_1000_childs\"] = dataset[\"pos_deaths_per_1000_childs\"].where(\n",
    "#         dataset['climate_band']!=zone,\n",
    "#         dataset[\"stdm_t_pos_9m\"] * high_temp_attributable_deaths_1year_iushocks + \n",
    "#         dataset[\"stdm_t_pos_6m\"] * high_temp_attributable_deaths_1year_1yearshock \n",
    "#     )\n",
    "#     dataset[\"neg_deaths_per_1000_childs\"] = dataset[\"neg_deaths_per_1000_childs\"].where(\n",
    "#         dataset['climate_band']!=zone,\n",
    "#         dataset[\"stdm_t_neg_9m\"] * -low_temp_attributable_deaths_1year_iushocks + \n",
    "#         dataset[\"stdm_t_neg_6m\"] * -low_temp_attributable_deaths_1year_1yearshock \n",
    "#     )\n",
    "\n",
    "# dataset[\"n_childs\"] = dataset[\"total_population\"] * dataset[\"born_ratio\"]\n",
    "# dataset[\"pos_deaths\"] = dataset[\"n_childs\"] * dataset[\"pos_deaths_per_1000_childs\"] / 1000\n",
    "# dataset[\"neg_deaths\"] = dataset[\"n_childs\"] * dataset[\"neg_deaths_per_1000_childs\"] / 1000\n",
    "\n",
    "# dataset[\"pos_deaths_per_1000_childs\"] = dataset[\"pos_deaths_per_1000_childs\"].where(dataset[\"pos_deaths\"].notnull(), np.nan)\n",
    "# dataset[\"neg_deaths_per_1000_childs\"] = dataset[\"neg_deaths_per_1000_childs\"].where(dataset[\"neg_deaths\"].notnull(), np.nan)\n",
    "# dataset[\"deaths_per_1000_childs\"] = dataset[\"pos_deaths_per_1000_childs\"] + dataset[\"neg_deaths_per_1000_childs\"]\n",
    "\n",
    "# dataset[\"total_deaths\"] = dataset[\"neg_deaths\"] + dataset[\"pos_deaths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c55d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_temp_attributable_deaths_1year_iushocks = (1.5 + .4 + 1.1 + 0.6)\n",
    "# high_temp_attributable_deaths_1year_1yearshock = (1.1 + 0.6)\n",
    "# low_temp_attributable_deaths_1year_iushocks = (1.7 + 0.7 + 0.6)\n",
    "# low_temp_attributable_deaths_1year_1yearshock = (1.2 + 0.5 + 0.6)\n",
    "\n",
    "# print(f\"High Temp Attributable Deaths in the first year (in utero shocks): {high_temp_attributable_deaths_1year_iushocks}\")\n",
    "# print(f\"Low Temp Attributable Deaths in the first year (in utero shocks): {low_temp_attributable_deaths_1year_iushocks}\")\n",
    "# print(f\"High Temp Attributable Deaths in the first year (1st year shocks): {high_temp_attributable_deaths_1year_1yearshock}\")\n",
    "# print(f\"Low Temp Attributable Deaths in the first year (1st year shocks): {low_temp_attributable_deaths_1year_1yearshock}\")\n",
    "\n",
    "# dataset[\"pos_deaths_per_1000_childs\"] = (\n",
    "#     dataset[\"stdm_t_pos_9m\"] * high_temp_attributable_deaths_1year_iushocks + \n",
    "#     dataset[\"stdm_t_pos_6m\"] * high_temp_attributable_deaths_1year_1yearshock \n",
    "# )\n",
    "# dataset[\"neg_deaths_per_1000_childs\"] = (\n",
    "#     dataset[\"stdm_t_neg_9m\"] * -low_temp_attributable_deaths_1year_iushocks + \n",
    "#     dataset[\"stdm_t_neg_6m\"] * -low_temp_attributable_deaths_1year_1yearshock \n",
    "# )\n",
    "\n",
    "# dataset[\"n_childs\"] = dataset[\"total_population\"] * dataset[\"born_ratio\"]\n",
    "# dataset[\"pos_deaths\"] = dataset[\"n_childs\"] * dataset[\"pos_deaths_per_1000_childs\"] / 1000\n",
    "# dataset[\"neg_deaths\"] = dataset[\"n_childs\"] * dataset[\"neg_deaths_per_1000_childs\"] / 1000\n",
    "\n",
    "# dataset[\"pos_deaths_per_1000_childs\"] = dataset[\"pos_deaths_per_1000_childs\"].where(dataset[\"pos_deaths\"].notnull(), np.nan)\n",
    "# dataset[\"neg_deaths_per_1000_childs\"] = dataset[\"neg_deaths_per_1000_childs\"].where(dataset[\"neg_deaths\"].notnull(), np.nan)\n",
    "# dataset[\"deaths_per_1000_childs\"] = dataset[\"pos_deaths_per_1000_childs\"] + dataset[\"neg_deaths_per_1000_childs\"]\n",
    "\n",
    "# dataset[\"total_deaths\"] = dataset[\"neg_deaths\"] + dataset[\"pos_deaths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387502c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# --- Main plotting code ---\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 5), sharex=True, sharey=True)\n",
    "# fig.suptitle('Annual Climate Shock Deaths attributable to Temperature Anomalies', fontsize=16)\n",
    "\n",
    "whole_world.plot(color=\"lightgray\", ax=ax)\n",
    "ax.set_axis_off()\n",
    "\n",
    "# --- Plot 3: Low Temperature Deaths per 1,000 children born ---\n",
    "ax3 = ax\n",
    "neg_rel_deaths = dataset[\"deaths_per_1000_childs\"].sel(y=slice(-60, 75)).mean(dim=\"time\")\n",
    "quintile_breaks = np.nanpercentile(neg_rel_deaths, [10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "plot_levels = np.unique([neg_rel_deaths.min()] + list(quintile_breaks) + [neg_rel_deaths.max()])\n",
    "neg_rel_deaths.plot(\n",
    "    ax=ax3,\n",
    "    cmap='YlOrRd',  # Using a different colormap for clarity\n",
    "    levels=plot_levels,\n",
    "    cbar_kwargs={\n",
    "        'label': 'Deaths per 1000 Children born alive',\n",
    "        'format': '%.1f',  # Add this line to format the color bar labels\n",
    "}\n",
    ")\n",
    "ax3.set_title(\"\", fontsize=14)\n",
    "\n",
    "# Adjust layout to prevent title overlap and display the plot\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig(r\"C:\\Working Papers\\Paper - Child Mortality and Climate Shocks\\Outputs\\Figures\\deaths_mapping_both.png\", dpi=450, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# --- Main plotting code ---\n",
    "fig, axs = plt.subplots(3, 1, figsize=(30, 12), sharex=True, sharey=True)\n",
    "# fig.suptitle('Annual Climate Shock Deaths attributable to Temperature Anomalies', fontsize=16)\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    whole_world.plot(color=\"lightgray\", ax=ax)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "# --- Plot 1: Positive Deaths per 1,000 children born ---\n",
    "ax1 = axs[0]\n",
    "pos_rel_deaths = dataset[\"pos_deaths_per_1000_childs\"].sel(y=slice(-60, 75)).mean(dim=\"time\")\n",
    "\n",
    "# Calculate the quintile breaks (20th, 40th, 60th, 80th percentiles)\n",
    "quintile_breaks = np.nanpercentile(pos_rel_deaths, [10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "# Create the final list of levels for plotting, including the min and max\n",
    "plot_levels = np.unique([pos_rel_deaths.min()] + list(quintile_breaks) + [pos_rel_deaths.max()])\n",
    "\n",
    "# Plot with discrete levels\n",
    "pos_rel_deaths.plot(\n",
    "    ax=ax1,\n",
    "    cmap='Reds',\n",
    "    levels=plot_levels,\n",
    "    cbar_kwargs={'label': 'Deaths per 1000 Children born alive'}\n",
    ")\n",
    "ax1.set_title(\"High Temperature Shocks\", fontsize=14)\n",
    "\n",
    "\n",
    "# --- Plot 2: Low Temperature Deaths per 1,000 children born ---\n",
    "ax2 = axs[1]\n",
    "neg_rel_deaths = dataset[\"neg_deaths_per_1000_childs\"].sel(y=slice(-60, 75)).mean(dim=\"time\")\n",
    "quintile_breaks = np.nanpercentile(neg_rel_deaths, [10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "plot_levels = np.unique([neg_rel_deaths.min()] + list(quintile_breaks) + [neg_rel_deaths.max()])\n",
    "neg_rel_deaths.plot(\n",
    "    ax=ax2,\n",
    "    cmap='Blues',  # Using a different colormap for clarity\n",
    "    levels=plot_levels,\n",
    "    cbar_kwargs={'label': 'Deaths per 1000 Children born alive'}\n",
    ")\n",
    "ax2.set_title(\"Low Temperature Shocks\", fontsize=14)\n",
    "\n",
    "# --- Plot 3: Low Temperature Deaths per 1,000 children born ---\n",
    "ax3 = axs[2]\n",
    "neg_rel_deaths = dataset[\"deaths_per_1000_childs\"].sel(y=slice(-60, 75)).mean(dim=\"time\")\n",
    "quintile_breaks = np.nanpercentile(neg_rel_deaths, [10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "plot_levels = np.unique([neg_rel_deaths.min()] + list(quintile_breaks) + [neg_rel_deaths.max()])\n",
    "neg_rel_deaths.plot(\n",
    "    ax=ax3,\n",
    "    cmap='Purples',  # Using a different colormap for clarity\n",
    "    levels=plot_levels,\n",
    "    cbar_kwargs={'label': 'Deaths per 1000 Children born alive'}\n",
    ")\n",
    "ax3.set_title(\"Both Temperature Shocks\", fontsize=14)\n",
    "\n",
    "# # --- Plot 3: Positive Total Deaths ---\n",
    "# ax3 = axs[0][1]\n",
    "# pos_deaths = dataset[\"pos_deaths\"].sel(y=slice(-60, 75)).mean(dim=\"time\")\n",
    "# quintile_breaks = np.nanpercentile(pos_deaths, [10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "# plot_levels = np.unique([pos_deaths.min()] + list(quintile_breaks) + [pos_deaths.max()])\n",
    "# pos_deaths.plot(\n",
    "#     ax=ax3,\n",
    "#     cmap='Reds',\n",
    "#     levels=plot_levels,\n",
    "#     # cbar_kwargs={'label': 'Total Deaths'}\n",
    "# )\n",
    "# ax3.set_title(\"High Temperature Shocks - Total Deaths\", fontsize=16)\n",
    "\n",
    "\n",
    "# # --- Plot 4: Low Temperature Total Deaths ---\n",
    "# ax4 = axs[1][1]\n",
    "# neg_deaths = dataset[\"neg_deaths\"].sel(y=slice(-60, 75)).mean(dim=\"time\")\n",
    "# quintile_breaks = np.nanpercentile(neg_deaths, [10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "# plot_levels = np.unique([neg_deaths.min()] + list(quintile_breaks) + [neg_deaths.max()])\n",
    "# neg_deaths.plot(\n",
    "#     ax=ax4,\n",
    "#     cmap='Blues', # Using a different colormap for clarity\n",
    "#     levels=plot_levels,\n",
    "#     # cbar_kwargs={'label': 'Total Deaths'}\n",
    "# )\n",
    "# ax4.set_title(\"Low Temperature Shocks - Total Deaths\", fontsize=16)\n",
    "\n",
    "# Adjust layout to prevent title overlap and display the plot\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig(r\"C:\\Working Papers\\Paper - Child Mortality and Climate Shocks\\Outputs\\Figures\\deaths_mapping.png\", dpi=450, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faff2588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,6) )\n",
    "dataset.total_deaths.sum(dim=[\"x\", \"y\"]).sel(time=slice(\"2000-01-01\",None)).plot(ax=ax)\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "ax.get_yaxis().set_major_formatter(\n",
    "    matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_title(\"Monthly Number of Deaths Attributable to Temperature Anomalies (2000-2022)\")\n",
    "sns.despine()\n",
    "plt.savefig(r\"C:\\Working Papers\\Paper - Child Mortality and Climate Shocks\\Outputs\\Figures\\deaths_over_time.png\", dpi=450, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ac3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.total_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# 1. Prepare the data for each variable\n",
    "# Sum pos_deaths and neg_deaths over the spatial dimensions and select the time slice\n",
    "time_slice = slice(\"1990-01-01\", None)\n",
    "heat_deaths = dataset.pos_deaths.sum(dim=[\"x\", \"y\"]).sel(time=time_slice)\n",
    "cold_deaths = dataset.neg_deaths.sum(dim=[\"x\", \"y\"]).sel(time=time_slice)\n",
    "\n",
    "# Extract the time coordinates for the x-axis\n",
    "time_axis = heat_deaths.time.values\n",
    "\n",
    "# 2. Create the plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "# 3. Use ax.stackplot to create the stacked area chart\n",
    "ax.stackplot(\n",
    "    time_axis,\n",
    "    heat_deaths.values,\n",
    "    cold_deaths.values,\n",
    "    labels=['Heat Attributable Deaths', 'Cold Attributable Deaths'],\n",
    "    colors=['#d1101f', \"#1f91b4\"], # A red for heat and a blue for cold\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "# 2. Define the start and end dates as datetime objects\n",
    "start_date = datetime.datetime(1992, 1, 1)\n",
    "end_date = datetime.datetime(2022, 12, 31)\n",
    "\n",
    "# 3. Apply the limits to the x-axis\n",
    "ax.set_xlim(start_date, end_date)\n",
    "\n",
    "# 4. Add a legend to identify the stacked areas\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "# --- The rest of your formatting remains the same ---\n",
    "\n",
    "# Format the y-axis to have commas for thousands\n",
    "ax.get_yaxis().set_major_formatter(\n",
    "    FuncFormatter(lambda x, p: format(int(x), ','))\n",
    ")\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel(\"Monthly Attributable Deaths\")\n",
    "ax.set_xlabel(\"\")\n",
    "\n",
    "# Clean up the plot aesthetics\n",
    "sns.despine()\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(r\"C:\\Working Papers\\Paper - Child Mortality and Climate Shocks\\Outputs\\Figures\\deaths_over_time_stacked.png\", dpi=450, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a834118",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea24e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.total_deaths.sel(time=slice(\"2000-01-01\",None)).sum(dim=[\"x\", \"y\", \"time\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
