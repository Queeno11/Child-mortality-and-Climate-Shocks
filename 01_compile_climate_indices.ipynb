{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Climate Database:\n",
    "\n",
    "Data for this version ERA5-Land_CHIRPS_monthly_1990-2021 combines CHIRPS precipitation data from GDO_Standardized_Precipitation_Index (https://drought.emergency.copernicus.eu/data/Drought_Observatories_datasets/) (https://data.jrc.ec.europa.eu/dataset/d955da08-0348-46a7-9c17-d28cdc3ba805) and ERA5-Land data for temperature. Instead of using the original ERA5 data, we used climate_shocks_v6 that have the temperature, standardized temperature and anomalies already computed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19  11:19:39 INFO To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "2024-09-19  11:19:39 INFO State start\n",
      "2024-09-19  11:19:39 INFO Found stale lock file and directory 'C:\\\\Users\\\\Nico\\\\AppData\\\\Local\\\\Temp\\\\dask-scratch-space\\\\scheduler-g13ly7xz', purging\n",
      "2024-09-19  11:19:39 INFO Found stale lock file and directory 'C:\\\\Users\\\\Nico\\\\AppData\\\\Local\\\\Temp\\\\dask-scratch-space\\\\scheduler-nbkl6yn4', purging\n",
      "2024-09-19  11:19:39 INFO Found stale lock file and directory 'C:\\\\Users\\\\Nico\\\\AppData\\\\Local\\\\Temp\\\\dask-scratch-space\\\\scheduler-vz1l8djh', purging\n",
      "2024-09-19  11:19:39 INFO Found stale lock file and directory 'C:\\\\Users\\\\Nico\\\\AppData\\\\Local\\\\Temp\\\\dask-scratch-space\\\\worker-95_5kwuh', purging\n",
      "2024-09-19  11:19:39 INFO Found stale lock file and directory 'C:\\\\Users\\\\Nico\\\\AppData\\\\Local\\\\Temp\\\\dask-scratch-space\\\\worker-j970ir99', purging\n",
      "2024-09-19  11:19:39 INFO Found stale lock file and directory 'C:\\\\Users\\\\Nico\\\\AppData\\\\Local\\\\Temp\\\\dask-scratch-space\\\\worker-khj91gvv', purging\n",
      "2024-09-19  11:19:39 INFO Found stale lock file and directory 'C:\\\\Users\\\\Nico\\\\AppData\\\\Local\\\\Temp\\\\dask-scratch-space\\\\worker-w1g40c1d', purging\n",
      "2024-09-19  11:19:39 INFO Found stale lock file and directory 'C:\\\\Users\\\\Nico\\\\AppData\\\\Local\\\\Temp\\\\dask-scratch-space\\\\worker-w5djjqnx', purging\n",
      "2024-09-19  11:19:39 INFO Found stale lock file and directory 'C:\\\\Users\\\\Nico\\\\AppData\\\\Local\\\\Temp\\\\dask-scratch-space\\\\worker-xrtgujtl', purging\n",
      "2024-09-19  11:19:39 INFO   Scheduler at:     tcp://127.0.0.1:50794\n",
      "2024-09-19  11:19:39 INFO   dashboard at:  http://127.0.0.1:8787/status\n",
      "2024-09-19  11:19:39 INFO Registering Worker plugin shuffle\n",
      "2024-09-19  11:19:39 INFO         Start Nanny at: 'tcp://127.0.0.1:50799'\n",
      "2024-09-19  11:19:39 INFO         Start Nanny at: 'tcp://127.0.0.1:50803'\n",
      "2024-09-19  11:19:39 INFO         Start Nanny at: 'tcp://127.0.0.1:50797'\n",
      "2024-09-19  11:19:39 INFO         Start Nanny at: 'tcp://127.0.0.1:50801'\n",
      "2024-09-19  11:19:41 INFO Register worker <WorkerState 'tcp://127.0.0.1:50813', name: 0, status: init, memory: 0, processing: 0>\n",
      "2024-09-19  11:19:41 INFO Starting worker compute stream, tcp://127.0.0.1:50813\n",
      "2024-09-19  11:19:41 INFO Starting established connection to tcp://127.0.0.1:50815\n",
      "2024-09-19  11:19:41 INFO Register worker <WorkerState 'tcp://127.0.0.1:50816', name: 1, status: init, memory: 0, processing: 0>\n",
      "2024-09-19  11:19:41 INFO Starting worker compute stream, tcp://127.0.0.1:50816\n",
      "2024-09-19  11:19:41 INFO Starting established connection to tcp://127.0.0.1:50818\n",
      "2024-09-19  11:19:41 INFO Register worker <WorkerState 'tcp://127.0.0.1:50819', name: 3, status: init, memory: 0, processing: 0>\n",
      "2024-09-19  11:19:41 INFO Starting worker compute stream, tcp://127.0.0.1:50819\n",
      "2024-09-19  11:19:41 INFO Starting established connection to tcp://127.0.0.1:50821\n",
      "2024-09-19  11:19:41 INFO Register worker <WorkerState 'tcp://127.0.0.1:50822', name: 2, status: init, memory: 0, processing: 0>\n",
      "2024-09-19  11:19:41 INFO Starting worker compute stream, tcp://127.0.0.1:50822\n",
      "2024-09-19  11:19:41 INFO Starting established connection to tcp://127.0.0.1:50824\n",
      "2024-09-19  11:19:41 INFO Receive client connection: Client-344454ce-7692-11ef-8558-408d5c1ef16e\n",
      "2024-09-19  11:19:41 INFO Starting established connection to tcp://127.0.0.1:50825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:50794' processes=4 threads=4, memory=31.88 GiB>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from climate_indices import indices, compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client\n",
    "\n",
    "# Set global variables\n",
    "PROJECT = r\"D:\\World Bank\\Paper - Child mortality and Climate Shocks\"\n",
    "OUTPUTS = rf\"{PROJECT}\\Outputs\"\n",
    "DATA = rf\"{PROJECT}\\Data\"\n",
    "DATA_IN = rf\"{DATA}\\Data_in\"\n",
    "DATA_PROC = rf\"{DATA}\\Data_proc\"\n",
    "DATA_OUT = rf\"{DATA}\\Data_out\"\n",
    "ERA5_DATA = rf\"D:\\Datasets\\ERA5 Reanalysis\\monthly-land\"\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "client = Client()  # start distributed scheduler locally.\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spis = []\n",
    "for spi in [\"1\", \"3\", \"6\", \"9\",\"12\",\"24\",\"48\"]:\n",
    "\n",
    "    spi_path = rf\"D:\\Datasets\\GDO Standardized Precipitation Index CHIRPS\\spi{spi}\"\n",
    "    files = os.listdir(spi_path)\n",
    "\n",
    "    ncs = []\n",
    "    for f in files:\n",
    "        match = re.search(r'_(\\d{8})_(\\d{8})_', f)\n",
    "\n",
    "        if match:\n",
    "            year = match.group(1)[:4]\n",
    "\n",
    "        if int(year)>2020:\n",
    "            continue    \n",
    "        \n",
    "        prec = xr.open_dataset(os.path.join(spi_path, f), chunks={\"lat\":90, \"lon\":90, \"time\":-1})\n",
    "        \n",
    "        drop_vars = [var for var in prec.data_vars if f\"spg{spi.zfill(2)}\"!=var]\n",
    "        prec = prec.drop_vars(drop_vars)\n",
    "        \n",
    "        prec = prec.rename({f\"spg{spi.zfill(2)}\":f\"spi{spi}\"})\n",
    "\n",
    "        ncs += [prec]\n",
    "\n",
    "    ds = xr.combine_by_coords(ncs)\n",
    "    spis += [ds]\n",
    "\n",
    "spis = xr.merge(spis)\n",
    "spis.to_netcdf(r\"D:\\World Bank\\Paper - Child Mortality and Climate Shocks\\Data\\Data_proc\\Climate_shocks_v7_spi.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
